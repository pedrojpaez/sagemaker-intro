{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PyTorch MNIST Classifier - Local Example\n",
    "\n",
    "_**Train and export a PyTorch CNN classifier for (a subset of) the [MNIST DIGITS](https://en.wikipedia.org/wiki/MNIST_database) dataset: Performing all storage and computation locally on the notebook.**_\n",
    "\n",
    "This notebook works well with the `Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)` kernel on SageMaker Studio, or `conda_pytorch_p36` on classic SageMaker Notebook Instances.\n",
    "\n",
    "---\n",
    "\n",
    "To give a better idea of how you might **apply the example to real-world problems**, we **convert the dataset** from its standard pixel array format to a \"folders of JPEGs\" setting more typical in image classification projects just starting out. For MNIST (where the images are all tiny and uniform size), this is a much less efficient storage method - so we sample a subset of the data to keep things performant.\n",
    "\n",
    ">‚ùì*Can you figure out how to re-create this notebook's workflow using SageMaker more effectively?*\n",
    "\n",
    "## Contents\n",
    "\n",
    "1. [Explore the Data](#Explore-the-Data)\n",
    "1. [Convert the Data Format](#Convert-the-Data-Format)\n",
    "1. **[Load the Data From File](#Load-the-Data-From-File)** *\n",
    "1. **[Pre-Process the Data for our CNN](#Pre-Process-the-Data-for-our-CNN)** *\n",
    "1. **[Build a Model](#Build-a-Model)** *\n",
    "1. **[Fit the Model](#Fit-the-Model)** *\n",
    "1. **[Save the Trained Model](#Save-the-Trained-Model)** *\n",
    "1. [Explore Results](#Explore-Results)\n",
    "\n",
    "See the accompanying **Instructions** notebook for more guidance!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# First install some libraries which might not be available across all kernels (e.g. in Studio):\n",
    "!pip install ipywidgets matplotlib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "print(f\"Using PyTorch version {torch.__version__}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore the Data\n",
    "\n",
    "Let's use the built-in function to load the MNIST data, but explore exactly what format that gives us:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_dataset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=None)\n",
    "\n",
    "# To keep things snappy for the exercise (you'll see why later), we will scale back the data:\n",
    "usable = int(len(mnist_dataset)/2)\n",
    "train_set, delete_set = torch.utils.data.random_split(mnist_dataset, [usable, len(mnist_dataset)-usable])\n",
    "del delete_set\n",
    "\n",
    "train_part = int(0.84*usable)\n",
    "train_set, test_set = torch.utils.data.random_split(train_set, [train_part, usable-train_part])\n",
    "x_train_raw, y_train_raw = map(list,zip(*train_set))\n",
    "x_test_raw, y_test_raw = map(list,zip(*test_set))\n",
    "\n",
    "x_train_raw = list(map(np.asarray,x_train_raw))\n",
    "x_train_raw = np.array(x_train_raw)\n",
    "y_train_raw = np.array(y_train_raw)\n",
    "x_test_raw = list(map(np.asarray,x_test_raw))\n",
    "x_test_raw = np.array(x_test_raw)\n",
    "y_test_raw = np.array(y_test_raw)\n",
    "\n",
    "print(f\"x_train.shape {x_train_raw.shape}; dtype {x_train_raw.dtype}\")\n",
    "print(f\"y_train.shape {y_train_raw.shape}; dtype {y_train_raw.dtype}\")\n",
    "print(f\"x_test.shape {x_test_raw.shape}; dtype {x_test_raw.dtype}\")\n",
    "print(f\"y_test.shape {y_test_raw.shape}; dtype {y_test_raw.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train_raw.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train_raw)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like the data is pretty evenly distributed between labels 0-9, and our images are encoded by fixed-size 28x28 uint8 matrices from 0 to 255. Here we'll just plot a few examples to get a feel for them:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    fig = plt.subplot(1, 5, i + 1)\n",
    "    ax = plt.imshow(x_train_raw[i], cmap=\"gray\")\n",
    "    fig.set_title(f\"Number {y_train_raw[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convert the Data Format\n",
    "\n",
    "Now let's create a folder for each class 0-9, and save all the images in their associated folder... It's a bit easier to relate to than the pre-prepared numpy arrays!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from tqdm.notebook import tqdm  # Progress bar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "!rm -rf data/train\n",
    "!rm -rf data/test\n",
    "\n",
    "# This can take a while due to the number of images\n",
    "def save_to_disk(x, y, base_folder):\n",
    "    \"\"\"Save an image classification dataset to disk as JPEGs in label-named folders\"\"\"\n",
    "    transform = torchvision.transforms.ToPILImage(\"L\")\n",
    "    # Create the digit folders up-front for speed:\n",
    "    for d in range(10):\n",
    "        label_str = \"digit-%d\" % d\n",
    "        os.makedirs(os.path.join(base_folder, label_str), exist_ok=True)\n",
    "\n",
    "    for ix in tqdm(range(len(y))):\n",
    "        label_str = \"digit-%d\" % y[ix]\n",
    "        transform(x[ix]).save(os.path.join(base_folder, label_str, \"%s-%06d.jpg\" % (label_str, ix)))\n",
    "\n",
    "print(\"Saving training data...\")\n",
    "os.makedirs(\"data/train\", exist_ok=True)\n",
    "save_to_disk(x_train_raw, y_train_raw, \"data/train\")\n",
    "print(\"Saving test data...\")\n",
    "os.makedirs(\"data/test\", exist_ok=True)\n",
    "save_to_disk(x_test_raw, y_test_raw, \"data/test\")\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data From File\n",
    "\n",
    "Now our images are stored in the `data/` folder, let's ignore the Keras built-in method and read our training and test sets in from these files.\n",
    "\n",
    "```\n",
    "    ./data\n",
    "    |----------------.\n",
    "    `-- test          `-- train\n",
    "        |-- digit-0       |-- digit-0\n",
    "        |                     `-- digit-0-000001.jpg, etc.\n",
    "        |-- digit-1       |-- digit-1\n",
    "        |-- digit-2       |-- digit-2\n",
    "        |-- digit-3       |-- digit-3\n",
    "        |-- digit-4       |-- digit-4\n",
    "        |-- digit-5       |-- digit-5\n",
    "        |-- digit-6       |-- digit-6\n",
    "        |-- digit-7       |-- digit-7\n",
    "        |-- digit-8       |-- digit-8\n",
    "        `-- digit-9       `-- digit-9\n",
    "```\n",
    "\n",
    "(For both training and test) We'll loop through each folder taking the target label (`0`-`9`) from the folder name and loading loading each JPEG into an image matrix.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "labels = sorted(os.listdir(\"data/train\"))\n",
    "n_labels = len(labels)\n",
    "\n",
    "x_train = []\n",
    "y_train = []\n",
    "x_test = []\n",
    "y_test = []\n",
    "print(\"Loading label \", end=\"\")\n",
    "for ix_label in range(n_labels):\n",
    "    label_str = labels[ix_label]\n",
    "    print(f\"{label_str}...\", end=\"\")\n",
    "    trainfiles = filter(\n",
    "        lambda s: s.endswith(\".jpg\"),\n",
    "        os.listdir(os.path.join(\"data/train\", label_str))\n",
    "    )\n",
    "    for filename in trainfiles:\n",
    "        with open(os.path.join(\"data/train\", label_str, filename), \"rb\") as imgfile:\n",
    "            x_train.append(\n",
    "                np.squeeze(np.asarray(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_train.append(ix_label)\n",
    "    # Repeat for test data:\n",
    "    testfiles = filter(\n",
    "        lambda s: s.endswith(\".jpg\"),\n",
    "        os.listdir(os.path.join(\"data/test\", label_str))\n",
    "    )\n",
    "    for filename in testfiles:\n",
    "        with open(os.path.join(\"data/test\", label_str, filename), \"rb\") as imgfile:\n",
    "            x_test.append(\n",
    "                np.squeeze(np.asarray(\n",
    "                    Image.open(imgfile)\n",
    "                ))\n",
    "            )\n",
    "            y_test.append(ix_label)\n",
    "\n",
    "print(\"Shuffling trainset...\")\n",
    "train_shuffled = [(x_train[ix], y_train[ix]) for ix in range(len(y_train))]\n",
    "np.random.shuffle(train_shuffled)\n",
    "\n",
    "x_train = np.array([datum[0] for datum in train_shuffled])\n",
    "y_train = np.array([datum[1] for datum in train_shuffled])\n",
    "train_shuffled = None\n",
    "\n",
    "print(\"Shuffling testset...\")\n",
    "test_shuffled = [(x_test[ix], y_test[ix]) for ix in range(len(y_test))]\n",
    "np.random.shuffle(test_shuffled)\n",
    "\n",
    "x_test = np.array([datum[0] for datum in test_shuffled])\n",
    "y_test = np.array([datum[1] for datum in test_shuffled])\n",
    "test_shuffled = None\n",
    "\n",
    "print(\"Done!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before we go ahead**, let's just quickly validate that the data is the same distribution as the original... Just shuffled in order:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"x_train.shape {x_train.shape}; dtype {x_train.dtype}\")\n",
    "print(f\"y_train.shape {y_train.shape}; dtype {y_train.dtype}\")\n",
    "print(f\"x_test.shape {x_test.shape}; dtype {x_test.dtype}\")\n",
    "print(f\"y_test.shape {y_test.shape}; dtype {y_test.dtype}\")\n",
    "\n",
    "fig = plt.figure(figsize=(14, 3))\n",
    "ax = plt.subplot(1, 2, 1)\n",
    "plt.hist(x_train.flatten())\n",
    "ax.set_title(\"Histogram of Training Image Data\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Pixel Value\")\n",
    "\n",
    "ax = plt.subplot(1, 2, 2)\n",
    "plt.hist(y_train)\n",
    "ax.set_title(\"Histogram of Training Set Labels\")\n",
    "ax.set_ylabel(\"Frequency in Training Set\")\n",
    "ax.set_xlabel(\"Y Label Value\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Some example images:\")\n",
    "fig = plt.figure(figsize=(14, 2))\n",
    "for i in range(5):\n",
    "    fig = plt.subplot(1, 5, i + 1)\n",
    "    ax = plt.imshow(x_train[i], cmap=\"gray\")\n",
    "    fig.set_title(f\"Number {y_train[i]}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "You should find that the distributions haven't shifted, and the advertised labels still visually match the images!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pre-Process the Data for our CNN\n",
    "\n",
    "We've recovered the dataset from our JPEG files back to the MNIST original format, and verified nothing's majorly broken...\n",
    "\n",
    "Next, we'll tweak this format for our neural network:\n",
    "\n",
    "- Normalizing pixel values to improve the numerical conditioning\n",
    "- One-hot encoding our labels to suit a softmax classifier output of probabilities for each digit\n",
    "- Adding both a batch dimension (for processing multiple samples in parallel) and a channel dimension (e.g. as if this were a 3-channel RGB image, except single-channel for grayscale) - as well as the X and Y axes.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = np.expand_dims(x_train, 1)\n",
    "x_test = np.expand_dims(x_test, 1)\n",
    "\n",
    "x_train = x_train.astype(\"float32\")\n",
    "x_test = x_test.astype(\"float32\")\n",
    "x_train /= 255\n",
    "x_test /= 255\n",
    "\n",
    "input_shape = x_train.shape[1:]\n",
    "\n",
    "print(\"x_train shape:\", x_train.shape)\n",
    "print(\"input_shape:\", input_shape)\n",
    "print(x_train.shape[0], \"train samples\")\n",
    "print(x_test.shape[0], \"test samples\")\n",
    "\n",
    "def to_categorical(y, num_classes):\n",
    "    \"\"\" 1-hot encodes a tensor \"\"\"\n",
    "    return np.eye(num_classes, dtype=\"float32\")[y]\n",
    "\n",
    "# convert class vectors to binary class matrices\n",
    "y_train = to_categorical(y_train, n_labels)\n",
    "y_test = to_categorical(y_test, n_labels)\n",
    "\n",
    "print(\"n_labels:\", n_labels)\n",
    "print(\"y_train shape:\", y_train.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build a Model\n",
    "\n",
    "At its core, the model is a 2D convolutional network with a softmax output layer that'll yield a confidence score for every possible label (e.g. 10 options for digit = 0 to 9).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Net(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(Net, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=(3, 3))\n",
    "        self.conv2 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=(3, 3))\n",
    "        self.max_pool2d = nn.MaxPool2d(kernel_size=(2, 2))\n",
    "        self.dropout1 = nn.Dropout2d(p=0.25)\n",
    "        self.flatten1 = nn.Flatten()\n",
    "        self.fc1 = nn.Linear(9216, 128)\n",
    "        self.dropout2 = nn.Dropout(p=0.5)\n",
    "        self.fc2 = nn.Linear(128, num_classes)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.flatten1(self.dropout1(self.max_pool2d(x)))\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.fc2(self.dropout2(x))\n",
    "        return F.softmax(x, dim=-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define training and evaluation script here"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def test(model, testloader, device):\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    model.eval()\n",
    "    test_loss = 0.0\n",
    "    correct = 0\n",
    "    with torch.no_grad():\n",
    "        for data, target in testloader:\n",
    "            data, target = data.to(device), target.to(device)\n",
    "            output = model(data)\n",
    "            test_loss += loss_function(output, target, reduction=\"mean\").item()  # sum up batch loss\n",
    "            pred = output.max(1, keepdim=True)[1]  # get the index of the max log-probability\n",
    "            target_index = target.max(1, keepdim=True)[1]\n",
    "            correct += pred.eq(target_index).sum().item()\n",
    "\n",
    "    test_loss /= len(testloader.dataset)\n",
    "    print(\"val_loss: {:.4f}\".format(test_loss))\n",
    "    print(\"val_acc: {:.4f}\".format(correct/len(testloader.dataset)))   \n",
    "\n",
    "def train(trainloader, testloader, epochs, num_classes):\n",
    "    model = Net(num_classes)\n",
    "    device = torch.device('cpu')\n",
    "    if torch.cuda.is_available():\n",
    "        device = torch.device('cuda')\n",
    "    model.to(device)\n",
    "    optimizer = torch.optim.Adadelta(model.parameters())\n",
    "    loss_function = F.binary_cross_entropy\n",
    "    \n",
    "    for epoch in range(1, epochs + 1):\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for batch_idx, (x_train, y_train) in enumerate(trainloader):\n",
    "            data, target = x_train.to(device), y_train.to(device)\n",
    "            optimizer.zero_grad()\n",
    "            output = model(data)\n",
    "            loss = loss_function(output, target)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "            running_loss += loss.item()\n",
    "        print(\"epoch: {}\".format(epoch))\n",
    "        print(\"train_loss: {:.6f}\".format(running_loss / (len(trainloader.dataset))))     \n",
    "        print(\"Evaluating model\")\n",
    "        test(model, testloader, device)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The custom Dataset class below is to allow data loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dataset(torch.utils.data.Dataset):\n",
    "    def __init__(self, data, labels):\n",
    "        \"\"\"Initialization\"\"\"\n",
    "        self.labels = labels\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Denotes the total number of samples\"\"\"\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        # Load data and get label\n",
    "        X = self.data[index]\n",
    "        y = self.labels[index]\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fit the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "batch_size = 128\n",
    "epochs = 12\n",
    "trainloader = torch.utils.data.DataLoader(\n",
    "    Dataset(x_train, y_train),\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    ")\n",
    "testloader = torch.utils.data.DataLoader(\n",
    "    Dataset(x_test, y_test),\n",
    "    batch_size=1,\n",
    "    shuffle=True,\n",
    ")\n",
    "\n",
    "model = train(trainloader, testloader, epochs = epochs, num_classes = 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save the Trained Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Torch JIT model allows us to store the inference script along with the model weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The export folder needs to be empty, or non-existent\n",
    "!rm -rf data/model/model.pth\n",
    "!mkdir data/model\n",
    "\n",
    "path = \"./data/model/model.pth\"\n",
    "\n",
    "x = torch.rand((1,1,28,28), dtype= torch.float)\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "m = torch.jit.trace(model, x)\n",
    "torch.jit.save(m, path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Explore Results\n",
    "\n",
    "Let's take a sample image from the test set, predict the label and plot it!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Choose an image:\n",
    "label = \"2\"\n",
    "filename = os.listdir(f\"data/test/digit-{label}\")[0]\n",
    "\n",
    "# Load the image:\n",
    "img = Image.open(f\"data/test/digit-{label}/{filename}\")\n",
    "input_data = np.squeeze(np.asarray(img)).astype(np.float32)/255\n",
    "input_data = np.expand_dims(np.expand_dims(input_data,0),0)\n",
    "input_data = torch.tensor(input_data)\n",
    "\n",
    "# Send to the model:\n",
    "model = model.cpu()\n",
    "model.eval()\n",
    "result = model(input_data)\n",
    "result = result.detach().numpy()[0]\n",
    "print(f\"Result confidences: {result}\")\n",
    "\n",
    "# Plot the result:\n",
    "plt.figure(figsize=(3, 3))\n",
    "fig = plt.subplot(1, 1, 1)\n",
    "ax = plt.imshow(img, cmap=\"gray\")\n",
    "fig.set_title(f\"Predicted Number {np.argmax(result)}\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "All done!\n"
   ]
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (PyTorch 1.6 Python 3.6 CPU Optimized)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:ap-southeast-1:492261229750:image/pytorch-1.6-cpu-py36-ubuntu16.04-v1"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
