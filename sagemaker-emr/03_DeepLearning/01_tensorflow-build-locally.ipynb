{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TensorFlow Locally Develop a Model\n",
    "\n",
    "This notebook is tested using `Data Science - Python 3 Kernel` running on a `ml.t3.medium` instance. Please ensure that you use `Python 3 (Data Science)` in the top right on your notebook.\n",
    "\n",
    "-----------------------\n",
    "BROKEN KERNEL (Fix should be imminent):\n",
    "\n",
    "This notebook is tested using `TensorFlow 2.6 Python 3.8 CPU Optimized - Python 3 Kernel` running on a `ml.t3.medium` instance. Please ensure that you see `Python 3 (TensorFlow 2.6 Python 3.8 CPU Optimized)` in the top right on your notebook.\n",
    "\n",
    "\n",
    "------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Overview\n",
    "\n",
    "In this notebook, we'll use a Studio notebook to protype our data loading and model architecture.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: If not installed (e.g in wrong kernel)\n",
    "%pip install tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading stored variables\n",
    " Run the cell below to load any prevously created variables from the prior notebook in this lab. You should see a print-out of the existing variables. If you don't see anything printed then you missed the final cell of the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stored variables and their in-db values:\n",
      "data_bucket             -> 'sagemaker-us-west-1-176842773820/nyc-taxi/data/pr\n"
     ]
    }
   ],
   "source": [
    "%store -r\n",
    "%store"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Important: You must have run the previous sequential notebooks to retrieve variables using the StoreMagic command.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Download Sample of data for local model building"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sagemaker\n",
    "\n",
    "data_bucket_s3_uri = \"s3://\" + data_bucket\n",
    "\n",
    "# Filter directory for csv files\n",
    "csv_files = [x for x in sagemaker.s3.S3Downloader.list(data_bucket_s3_uri) if x[-4:] == \".csv\"]\n",
    "\n",
    "# Download one csv file\n",
    "sagemaker.s3.S3Downloader.download(csv_files[0], \"demo_data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>day_of_week</th>\n",
       "      <th>month</th>\n",
       "      <th>hour</th>\n",
       "      <th>pickup_latitude</th>\n",
       "      <th>pickup_longitude</th>\n",
       "      <th>dropoff_latitude</th>\n",
       "      <th>dropoff_longitude</th>\n",
       "      <th>trip_distance</th>\n",
       "      <th>fare_amount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.575375</td>\n",
       "      <td>-73.969070</td>\n",
       "      <td>40.726715</td>\n",
       "      <td>40.726715</td>\n",
       "      <td>20.80</td>\n",
       "      <td>57.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.575977</td>\n",
       "      <td>-73.990845</td>\n",
       "      <td>40.656620</td>\n",
       "      <td>40.656620</td>\n",
       "      <td>12.00</td>\n",
       "      <td>41.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.576317</td>\n",
       "      <td>-73.981339</td>\n",
       "      <td>40.583519</td>\n",
       "      <td>40.583519</td>\n",
       "      <td>0.59</td>\n",
       "      <td>4.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.587311</td>\n",
       "      <td>-73.954010</td>\n",
       "      <td>40.631557</td>\n",
       "      <td>40.631557</td>\n",
       "      <td>3.90</td>\n",
       "      <td>15.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>40.587357</td>\n",
       "      <td>-73.954361</td>\n",
       "      <td>40.595753</td>\n",
       "      <td>40.595753</td>\n",
       "      <td>1.20</td>\n",
       "      <td>6.5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   day_of_week  month  hour  pickup_latitude  pickup_longitude  \\\n",
       "0            1      1     0        40.575375        -73.969070   \n",
       "1            1      1     0        40.575977        -73.990845   \n",
       "2            1      1     0        40.576317        -73.981339   \n",
       "3            1      1     0        40.587311        -73.954010   \n",
       "4            1      1     0        40.587357        -73.954361   \n",
       "\n",
       "   dropoff_latitude  dropoff_longitude  trip_distance  fare_amount  \n",
       "0         40.726715          40.726715          20.80         57.0  \n",
       "1         40.656620          40.656620          12.00         41.0  \n",
       "2         40.583519          40.583519           0.59          4.0  \n",
       "3         40.631557          40.631557           3.90         15.0  \n",
       "4         40.595753          40.595753           1.20          6.5  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "import pandas as pd\n",
    "\n",
    "csv_file = glob.glob(\"demo_data/*.csv\")[0]\n",
    "\n",
    "column_headers = [\"day_of_week\",\"month\",\"hour\",\"pickup_latitude\",\"pickup_longitude\",\n",
    "                  \"dropoff_latitude\",\"dropoff_longitude\",\"trip_distance\",\"fare_amount\"]\n",
    "\n",
    "raw_dataset = pd.read_csv(csv_file, names=column_headers)\n",
    "raw_dataset.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "linear_input = raw_dataset[[\"day_of_week\", \"month\", \"hour\", \"trip_distance\"]]\n",
    "dnn_input = raw_dataset[[\"pickup_latitude\",\"pickup_longitude\",\"dropoff_latitude\",\"dropoff_longitude\",\"trip_distance\"]]\n",
    "y = raw_dataset[[\"fare_amount\"]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Architecture Prototyping\n",
    "![image](https://1.bp.blogspot.com/-Dw1mB9am1l8/V3MgtOzp3uI/AAAAAAAABGs/mP-3nZQCjWwdk6qCa5WraSpK8A7rSPj3ACLcB/s1600/image04.png)\n",
    "\n",
    "https://ai.googleblog.com/2016/06/wide-deep-learning-better-together-with.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.experimental import LinearModel, WideDeepModel\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "4943/4943 [==============================] - 10s 2ms/step - loss: 47.1643 - mse: 47.1643\n",
      "Epoch 2/5\n",
      "4943/4943 [==============================] - 9s 2ms/step - loss: 17.9014 - mse: 17.9014\n",
      "Epoch 3/5\n",
      "4943/4943 [==============================] - 9s 2ms/step - loss: 17.7558 - mse: 17.7558\n",
      "Epoch 4/5\n",
      "4943/4943 [==============================] - 10s 2ms/step - loss: 17.7560 - mse: 17.7560\n",
      "Epoch 5/5\n",
      "4943/4943 [==============================] - 9s 2ms/step - loss: 17.7573 - mse: 17.7573\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7fbaa14ca290>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearModel()\n",
    "\n",
    "dnn_model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='elu'),  \n",
    "    keras.layers.Dense(64, activation='elu'), \n",
    "    keras.layers.Dense(32, activation='elu'), \n",
    "    keras.layers.Dense(1,activation='sigmoid') \n",
    "])\n",
    "\n",
    "combined_model = WideDeepModel(linear_model, dnn_model)\n",
    "combined_model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "combined_model.fit([linear_input, dnn_input], y, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF Native File Reader\n",
    "After an acceptable model tested using our pandas dataset, we need to think about what dataset we'll have when we scale this up to our entire dataset as a submitted SageMaker Training Job. To do this, we can prototype a notoriously tricky process right here in our local notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def pack(features, label):\n",
    "    linear_features = [tf.cast(features['day_of_week'], tf.float32), tf.cast(features['month'], tf.float32),\n",
    "                       tf.cast(features['hour'], tf.float32), features[\"trip_distance\"]]\n",
    "    \n",
    "    dnn_features = [features['pickup_latitude'], features['pickup_longitude'], features['dropoff_latitude'],\n",
    "                    features['dropoff_longitude'], features[\"trip_distance\"]]\n",
    "    \n",
    "    return (tf.stack(linear_features, axis=-1), tf.stack(dnn_features, axis=-1)), label\n",
    "\n",
    "\n",
    "ds = tf.data.experimental.make_csv_dataset(csv_file,\n",
    "                                           batch_size=1,\n",
    "                                           column_names=column_headers,\n",
    "                                           num_epochs=5,\n",
    "                                           shuffle=False,\n",
    "                                           label_name=\"fare_amount\")\n",
    "ds = ds.map(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([[ 1.  1.  0. 12.]], shape=(1, 4), dtype=float32)\n",
      "tf.Tensor([[ 40.575977 -73.990845  40.65662   40.65662   12.      ]], shape=(1, 5), dtype=float32)\n",
      "tf.Tensor([41.], shape=(1,), dtype=float32)\n"
     ]
    }
   ],
   "source": [
    "iterator = iter(ds)\n",
    "(x1, x2), y = next(iterator)\n",
    "\n",
    "print(x1)\n",
    "print(x2)\n",
    "print(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Build Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Increase Batch Size\n",
    "ds = tf.data.experimental.make_csv_dataset(csv_file,\n",
    "                                           batch_size=128,\n",
    "                                           column_names=column_headers,\n",
    "                                           num_epochs=1,\n",
    "                                           shuffle=False,\n",
    "                                           label_name=\"fare_amount\")\n",
    "ds = ds.map(pack)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "1236/1236 [==============================] - 5s 3ms/step - loss: 23.7142 - mse: 23.7142\n",
      "Epoch 2/5\n",
      "1236/1236 [==============================] - 4s 3ms/step - loss: 18.1587 - mse: 18.1587\n",
      "Epoch 3/5\n",
      "1236/1236 [==============================] - 4s 3ms/step - loss: 18.1560 - mse: 18.1560\n",
      "Epoch 4/5\n",
      "1236/1236 [==============================] - 4s 3ms/step - loss: 18.1392 - mse: 18.1392A\n",
      "Epoch 5/5\n",
      "1236/1236 [==============================] - 4s 3ms/step - loss: 18.1167 - mse: 18.1167\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.callbacks.History at 0x7f4c8212f8d0>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "linear_model = LinearModel()\n",
    "dnn_model = keras.Sequential([\n",
    "    keras.layers.Flatten(),\n",
    "    keras.layers.Dense(128, activation='elu'),  \n",
    "    keras.layers.Dense(64, activation='elu'), \n",
    "    keras.layers.Dense(32, activation='elu'), \n",
    "    keras.layers.Dense(1,activation='sigmoid') \n",
    "])\n",
    "combined_model = WideDeepModel(linear_model, dnn_model)\n",
    "combined_model.compile(optimizer=\"Adam\", loss=\"mse\", metrics=[\"mse\"])\n",
    "combined_model.fit(ds, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Lets Scale it out in the next Notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "instance_type": "ml.t3.medium",
  "kernelspec": {
   "display_name": "Python 3 (Data Science)",
   "language": "python",
   "name": "python3__SAGEMAKER_INTERNAL__arn:aws:sagemaker:us-west-1:742091327244:image/datascience-1.0"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
